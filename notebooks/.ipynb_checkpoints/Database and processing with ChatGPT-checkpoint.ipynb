{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9dabc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27cb67f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pickle.load(open('data/db_texts.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07c8fc53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b4fbc65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'created_at': datetime.datetime(2023, 9, 30, 19, 53, 2, tzinfo=datetime.timezone.utc),\n",
       " 'message_url': 'https://t.me/rian_ru/216890',\n",
       " 'type': 'video',\n",
       " 'channel': 'rian_ru',\n",
       " 'edited': False,\n",
       " 'url': nan,\n",
       " 'author': None,\n",
       " 'tg_preview_text': 'Школьным учителям в Дагестане рекомендовано отказаться от использования иностранных мессенджеров, в том числе WhatsApp, и перейти на отечественные аналоги, сообщили РИА Новости в Минобрнауки республики',\n",
       " 'source_url': nan,\n",
       " 'text': nan,\n",
       " 'meta_keywords': nan,\n",
       " 'authors': nan,\n",
       " 'twitter': nan,\n",
       " 'site_name': nan}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddd3464e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../flask_app/')\n",
    "import get_chatgpt_criteria\n",
    "import importlib\n",
    "importlib.reload(get_chatgpt_criteria)\n",
    "from get_chatgpt_criteria import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4946d4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_chatgpt_field(process_result, field):\n",
    "    parsed_manipulation_methods = []\n",
    "    lines = process_result[field].split('\\n')\n",
    "    for line in lines:\n",
    "        method = re.findall(r'(\\d+\\.(.*?)[:])', line)\n",
    "        if method:\n",
    "            method_name = method[0][1].strip()\n",
    "            if '(' in method_name:\n",
    "                method_example = re.findall(r'(\\((.*?)\\))', method_name)[0][0]\n",
    "                method_name = re.sub(r'\\s+', ' ', method_name.replace(method_example, '')).strip()\n",
    "            else:\n",
    "                method_example = ''\n",
    "            method_explanation = (method_example.strip() + \" \" + line.replace(method[0][0], '').strip()).strip()\n",
    "            parsed_manipulation_methods.append((method_name, method_explanation))\n",
    "    return parsed_manipulation_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4417dd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "telegram_record = sample[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "588ec1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2chatgpt_output = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3cd96579",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text2chatgpt_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38999a8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8923"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(x['text']) for x in sample if isinstance(x['text'], str)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f631ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median([len(x['text']) for x in sample if isinstance(x['text'], str)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7430a836",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median([len(x['tg_preview_text']) for x in sample if isinstance(x['text'], str)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d4d045d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2006"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max([len(x['tg_preview_text']) for x in sample if isinstance(x['text'], str)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "20e03ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2chatgpt_output = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5762e08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_stratified = []\n",
    "for source in set([s['channel'] for s in sample]):\n",
    "    sample_stratified.extend([r for r in sample if r['channel'] == source][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bcc311fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample_stratified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf16d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|██████████                                                                                | 337/3000 [02:51<7:52:22, 10.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(336, APIConnectionError(message=\"Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\", http_status=None, request_id=None), 'failed to process with chatgpt')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████▋                                                                            | 428/3000 [23:22<20:53:00, 29.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(427, APIConnectionError(message=\"Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\", http_status=None, request_id=None), 'failed to process with chatgpt')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████████████▏                                                                           | 444/3000 [27:47<19:31:07, 27.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(443, APIConnectionError(message=\"Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\", http_status=None, request_id=None), 'failed to process with chatgpt')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██████████████████▋                                                                       | 623/3000 [57:20<9:17:26, 14.07s/it]"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "all_parsed_manipulation_methods = []\n",
    "all_parsed_logical_fallacies = []\n",
    "errors = []\n",
    "db_records = []\n",
    "# LENGTH_THRESHOLD = {'MIN': 30, 'MAX': 2048}\n",
    "\n",
    "for i, telegram_record in enumerate(tqdm(sample)):\n",
    "    db_record = {}\n",
    "    text_to_check = ''\n",
    "    for field in ['tg_preview_text']:#, 'text']:\n",
    "        if isinstance(telegram_record[field], str):\n",
    "            text_to_check += telegram_record[field] + \" \"\n",
    "    text_to_check = text_to_check.strip()\n",
    "    if text_to_check:\n",
    "        if text_to_check in text2chatgpt_output:\n",
    "            process_result = text2chatgpt_output[text_to_check]\n",
    "        else:\n",
    "            try:\n",
    "                process_result = process_text(text_to_check)\n",
    "                text2chatgpt_output[text_to_check] = process_result\n",
    "            except Exception as e:\n",
    "                errors.append((i, e, 'failed to process with chatgpt'))\n",
    "                print((i, e, 'failed to process with chatgpt'))\n",
    "                process_result = {}\n",
    "    else:\n",
    "        process_result = {}\n",
    "    try:\n",
    "        db_record['text'] = telegram_record['tg_preview_text']\n",
    "        db_record['source'] = telegram_record['channel']\n",
    "        db_record['date'] = telegram_record['created_at'].strftime('%Y-%m-%d %H:%M:%S')\n",
    "        db_record['url'] = telegram_record['message_url']\n",
    "        db_record['platform'] = 'telegram'\n",
    "        db_record['full_text'] = telegram_record['text'] if isinstance(telegram_record['text'], str) else ''\n",
    "        db_record['title'] = telegram_record.get('title', '')\n",
    "    except Exception as e:\n",
    "        errors.append((i, e, 'failed to process telegram record'))\n",
    "        print((i, e, 'failed to process telegram record'))\n",
    "        db_record['text'] = 'unprocessed'\n",
    "        db_record['source'] = 'unprocessed'\n",
    "        db_record['date'] = 'unprocessed'\n",
    "        db_record['url'] = 'unprocessed'\n",
    "        db_record['platform'] = 'telegram'\n",
    "        db_record['full_text'] = 'unprocessed'\n",
    "        db_record['title'] = 'unprocessed'\n",
    "    if process_result:\n",
    "        try:\n",
    "            db_record['text_type'] = process_result['text_type'].lower()\n",
    "            db_record['source_references'] = process_result['references']\n",
    "            db_record['source_references_present'] = process_result['references_present']\n",
    "            db_record['logical_fallacies_present'] = process_result['logical_fallacies_present']\n",
    "            db_record['hatespeech_present'] = 0 if any(x in process_result['hatespeech'] for x in ['не найден', 'не обнаружен', 'отсутствует']) else 1\n",
    "            db_record['hatespeech_indicators'] = process_result['hatespeech']\n",
    "            parsed_manipulation_methods = parse_chatgpt_field(process_result, 'manipulation_methods')\n",
    "            all_parsed_manipulation_methods.append(parsed_manipulation_methods)\n",
    "            parsed_logical_fallacies = parse_chatgpt_field(process_result, 'logical_fallacies')\n",
    "            all_parsed_logical_fallacies.append(parsed_logical_fallacies)\n",
    "        except Exception as e:\n",
    "            errors.append((i, e, 'failed to parse chatgpt output'))\n",
    "            print((i, e, 'failed to parse chatgpt output'))\n",
    "    else:\n",
    "        db_record['text_type'] = 'undefined'\n",
    "        db_record['source_references'] = 'uncalculated'\n",
    "        db_record['source_references_present'] = 0\n",
    "        db_record['logical_fallacies_present'] = 0\n",
    "        db_record['hatespeech_present'] = 0\n",
    "        db_record['hatespeech_indicators'] = 'uncalculated'\n",
    "    db_records.append(db_record)\n",
    "    pickle.dump(text2chatgpt_output, open('text2chatgpt_output_sample_011023_temp0.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ed450ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'другое', 'новость', 'новостью', 'текст является новостью.'}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([db_record['text_type'] for db_record in db_records])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6938efbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_text_type(db_record_text_type):\n",
    "    for text_type in text_types:\n",
    "        if text_type in db_record_text_type:\n",
    "            return text_type\n",
    "    return 'другое'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "96570376",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from datetime import datetime\n",
    "\n",
    "# Connect to the SQLite database (or create a new one if it doesn't exist)\n",
    "conn = sqlite3.connect('sample_database.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "text_types = ('личное сообщение', 'статья', 'новость', 'запись в личном блоге', 'публичный комментарий', 'другое')\n",
    "# Create the 'texts' table\n",
    "cursor.execute(f'''\n",
    "    CREATE TABLE IF NOT EXISTS texts (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        text TEXT,\n",
    "        source TEXT,\n",
    "        text_type TEXT CHECK(text_type IN {text_types}),\n",
    "        date TIMESTAMP,\n",
    "        url TEXT,\n",
    "        platform TEXT,\n",
    "        full_text TEXT,\n",
    "        title TEXT,\n",
    "        source_references TEXT,\n",
    "        source_references_present BOOLEAN,\n",
    "        logical_fallacies_present BOOLEAN,\n",
    "        hatespeech_present BOOLEAN,\n",
    "        hatespeech_indicators TEXT)\n",
    "''')\n",
    "\n",
    "for db_record in db_records:\n",
    "\n",
    "    cursor.execute('''\n",
    "        INSERT INTO texts (\n",
    "            text, source, text_type, date, url, platform, full_text, title, source_references,\n",
    "            source_references_present, logical_fallacies_present,\n",
    "            hatespeech_present, hatespeech_indicators\n",
    "        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "    ''', (\n",
    "        db_record['text'], db_record['source'], simplify_text_type(db_record['text_type']),\n",
    "        db_record['date'], db_record['url'], db_record['platform'],\n",
    "        db_record['full_text'], db_record['title'], db_record['source_references'],\n",
    "        db_record['source_references_present'], db_record['logical_fallacies_present'],\n",
    "        db_record['hatespeech_present'], db_record['hatespeech_indicators']\n",
    "    ))\n",
    "    conn.commit()\n",
    "\n",
    "# Commit changes and close the connection\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6f0c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('sample_database.db')\n",
    "cursor = conn.cursor()\n",
    "# Create the 'manipulation_methods' table\n",
    "cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS manipulation_methods (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        manipulation_method_name TEXT)\n",
    "''')\n",
    "\n",
    "# Create the 'logical_fallacies' table\n",
    "cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS logical_fallacies (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        logical_fallacy_name TEXT)\n",
    "''')\n",
    "\n",
    "# Create the 'text_2_manipulation_methods' junction table\n",
    "cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS text_2_manipulation_methods (\n",
    "        text_id INTEGER,\n",
    "        manipulation_method_id INTEGER,\n",
    "        manipulation_method_explanation TEXT,\n",
    "        FOREIGN KEY (text_id) REFERENCES texts (id),\n",
    "        FOREIGN KEY (manipulation_method_id) REFERENCES manipulation_methods (id),\n",
    "        PRIMARY KEY (text_id, manipulation_method_id)\n",
    "    )\n",
    "''')\n",
    "\n",
    "\n",
    "# Create the 'text_2_logical_fallacies' junction table\n",
    "cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS text_2_logical_fallacies (\n",
    "        text_id INTEGER,\n",
    "        logical_fallacy_id INTEGER,\n",
    "        logical_fallacy_explanation TEXT,\n",
    "        FOREIGN KEY (text_id) REFERENCES texts (id),\n",
    "        FOREIGN KEY (logical_fallacy_id) REFERENCES manipulation_methods (id),\n",
    "        PRIMARY KEY (text_id, logical_fallacy_id)\n",
    "    )\n",
    "''')\n",
    "\n",
    "manipulation_methods = sorted(set([y[0] for x in all_parsed_manipulation_methods for y in x]))\n",
    "# Insert manipulation methods into the 'manipulation_methods' table\n",
    "for method in manipulation_methods:\n",
    "    cursor.execute('INSERT INTO manipulation_methods (manipulation_method_name) VALUES (?)', (method,))\n",
    "logical_fallacies = sorted(set([y[0] for x in all_parsed_logical_fallacies for y in x]))\n",
    "# Insert manipulation methods into the 'manipulation_methods' table\n",
    "for logical_fallacy in logical_fallacies:\n",
    "    cursor.execute('INSERT INTO logical_fallacies (logical_fallacy_name) VALUES (?)', (logical_fallacy,))\n",
    "    \n",
    "# Commit changes and close the connection\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b21526",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('sample_database.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Get the ID of the inserted texts article\n",
    "text_id = cursor.lastrowid\n",
    "\n",
    "# Associate manipulation methods with the texts article in the 'texts_manipulation' table\n",
    "for method in manipulation_methods:\n",
    "    cursor.execute('''\n",
    "        INSERT INTO text_2_manipulation_methods (text_id, manipulation_method_id)\n",
    "        VALUES (?, (SELECT id FROM manipulation_methods WHERE manipulation_method_name = ?))\n",
    "    ''', (text_id, method))\n",
    "\n",
    "# Commit changes and close the connection\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
